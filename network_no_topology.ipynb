{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fractopo â€“ Fracture Network Analysis\n",
    "\n",
    "Notebook that streamlines analysis when branches and nodes are not determined by user choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from shutil import rmtree, make_archive\n",
    "from fractopo.analysis.network import Network\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trace and target area data required. The paths can be urls to GeoJSON or local file paths to spatial filetypes (e.g. shapefile, geopackage). The name is used in plot labels and titles. \n",
    "\n",
    "1. Pass paths to your **validated** trace and area data here and name the analysis. E.g.,\n",
    "\n",
    "``` {python}\n",
    "trace_data = \"traces.gpkg\"\n",
    "area_data = \"target_area.gpkg\"\n",
    "name = \"my-analysis-name\"\n",
    "```\n",
    "   * The path is relative to the notebook directory. To make things easy you should've copied the notebook the working directory which       either directly contains your trace and area data or has the folder that does. Tab-completion works here aswell.\n",
    "    \n",
    "   * Note that the analysis name is used to create a folder like such `results/my-analysis-name` where all analysis results are saved to. If such a folder exists, all contents        will be overridden in the `my-analysis-name` folder.\n",
    "   * Note that the path is inside quotes. These are mandatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "trace_data = \"\"\n",
    "area_data = \"\"\n",
    "name = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The defaults in the next cell are only applied if no parameters are given to the above cell. This will result in a **default** analysis of a trace and area data downloaded from the urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(trace_data) == 0:\n",
    "    # Set defaults\n",
    "    # Trace and target area data available on GitHub\n",
    "    trace_data = \"data/KB11_traces.geojson\"\n",
    "    area_data = \"data/KB11_area.geojson\"\n",
    "    # Name the dataset\n",
    "    name = \"KB11\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The preselected analysis set can now be run! To run the notebook, click on the double-right-arrow on at the top of the notebook below the tab bar and click Restart.\n",
    "\n",
    "   * You can see the cells being executed with numbers appearing on the left.\n",
    "   * Some cells will take much longer than others depending on code execution time.\n",
    "   * Scroll down the notebook as the numbers appear until all cells have been reached.\n",
    "   * If the analysis throws errors they will appear in big red boxes.\n",
    "  \n",
    "**However**, you might want to change some defaults such as azimuth set ranges and set names and contour grid cell width. Scroll down to headers with ``USER INPUT:`` prefixes and follow the instructions there to configure default values.\n",
    "\n",
    "3. If no errors occur during running the results of the analysis will be in `results/my-analysis-name` folder (and an archived .zip).\n",
    "\n",
    "   * The folder will contain plots and spatial data files:\n",
    "   \n",
    "       * Rose plot of trace azimuths, length-weighted\n",
    "       * Length distribution plots\n",
    "       * XYI-plots\n",
    "       * Branches and nodes\n",
    "       * Contour grids\n",
    "       * Etc.\n",
    "   \n",
    "   * The folder has been also archived as a .zip file for easy downloading (`results/my-analysis-name.zip`).\n",
    "   \n",
    "   * If errors do occur:\n",
    "       \n",
    "       * Check the error message that occurred for possible solutions.\n",
    "       * Check that the trace and area paths are correct.\n",
    "       * You can restart the run from the same double-right-arrow symbol.\n",
    "       * Report errors that you can't solve at https://github.com/nialov/fractopo-help/issues\n",
    "\n",
    "4. Some analyses will be run with default settings which might not fit your dataset.\n",
    "\n",
    "    * This is especially the case for contour grids (grid cell size).\n",
    "    * Scroll down to the contour grid section to configure if the results are not to your liking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make/overwrite results dir\n",
    "results_dir = Path(\"results\") / f\"{name}_no_topology\"\n",
    "if results_dir.exists():\n",
    "    rmtree(results_dir)\n",
    "results_dir.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use geopandas to load data from urls/paths\n",
    "traces = gpd.read_file(trace_data)\n",
    "area = gpd.read_file(area_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area.total_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focus_plot_to_bounds(ax, total_bounds):\n",
    "    \"\"\"Focus plot to given bounds.\"\"\"\n",
    "    xmin, ymin, xmax, ymax = total_bounds\n",
    "    extend_x = (xmax - xmin) * 0.05\n",
    "    extend_y = (ymax - ymin) * 0.05\n",
    "    ax.set_xlim(xmin - extend_x, xmax + extend_x)\n",
    "    ax.set_ylim(ymin - extend_y, ymax + extend_y)\n",
    "    return ax\n",
    "\n",
    "\n",
    "def save_fig(fig, results_dir: Path, name: str):\n",
    "    \"\"\"Save figure as svg image to results dir.\"\"\"\n",
    "    fig.savefig(results_dir / f\"{name}.svg\", bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "def remove_duplicate_caseinsensitive_columns(columns) -> set:\n",
    "    \"\"\"Remove duplicate columns case-insensitively.\"\"\"\n",
    "    lower_case_columns = set(column.lower() for column in columns)\n",
    "    new_cols = set(columns)\n",
    "    for column in columns:\n",
    "        if column not in lower_case_columns and column.lower() in columns:\n",
    "            print(f\"Removing column ({column}) \")\n",
    "            new_cols.remove(column)\n",
    "    return new_cols\n",
    "\n",
    "\n",
    "def as_gpkg_and_shp(geodataframe, name, results_dir: Path = results_dir):\n",
    "    \"\"\"Save geodataframe as GeoPackage and as shapefile.\"\"\"\n",
    "    non_dupl_columns = remove_duplicate_caseinsensitive_columns(geodataframe.columns)\n",
    "    fid_col = \"fid\"\n",
    "    for column in geodataframe.columns:\n",
    "        if column not in non_dupl_columns:\n",
    "            print(f\"Dropping column: {column}\")\n",
    "            geodataframe.drop(columns=[column], inplace=True)\n",
    "        if column.lower() == fid_col:\n",
    "            # Remove fid columns\n",
    "            print(f\"Dropping column: {column} due to case-insensitive match to fid.\")\n",
    "            geodataframe.drop(columns=[column], inplace=True)\n",
    "    geodataframe.to_file(results_dir / f\"{name}.gpkg\", driver=\"GPKG\")\n",
    "    shp_dir = results_dir / f\"{name}_as_shp\"\n",
    "    shp_dir.mkdir()\n",
    "    geodataframe.to_file(shp_dir / f\"{name}.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing trace map data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 9))\n",
    "traces.plot(ax=ax, color=\"blue\")\n",
    "area.boundary.plot(ax=ax, color=\"red\")\n",
    "ax = focus_plot_to_bounds(ax, area.total_bounds)\n",
    "save_fig(fig, results_dir, \"base_visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USER INPUT: Pass your own azimuth sets\n",
    "\n",
    "You may pass your own azimuth sets here for e.g., cross-cutting and abutting relationship analysis. \n",
    "\n",
    "You must pass two types of values:\n",
    "\n",
    "1. Pass a range e.g., `(0, 60)` means the set contains lines with azimuths between 0 and 60 degrees.\n",
    "\n",
    "    * The range can circle around zero e.g. a range `(170, 30)` is accepted\n",
    "\n",
    "2. Pass the name for the range. Short names, possibly numerical are preferred e.g., `\"1\"` or `\"A\"`.\n",
    "3. Follow the below shown format and do not remove parenthesis or quotes. The inputs must be valid Python code.\n",
    "\n",
    "Each range must have an associated name. The inputted ranges must be in the same order as the names.\n",
    "\n",
    "#### Examples:\n",
    "\n",
    "Contains three sets:\n",
    "\n",
    "``` {python}\n",
    "azimuth_set_ranges = (\n",
    "    (0, 60),\n",
    "    (60, 120),\n",
    "    (120, 180),\n",
    ")\n",
    "azimuth_set_names = (\n",
    "    \"1\", \n",
    "    \"2\", \n",
    "    \"3\",\n",
    ")\n",
    "```\n",
    "\n",
    "Contains two sets:\n",
    "\n",
    "``` {python}\n",
    "azimuth_set_ranges = (\n",
    "    (0, 60),\n",
    "    (170, 30),\n",
    ")\n",
    "azimuth_set_names = (\n",
    "    \"A\", \n",
    "    \"B\",\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the default values. Input your values here and change the defaults (if needed).\n",
    "azimuth_set_ranges = (\n",
    "    (0, 60),\n",
    "    (60, 120),\n",
    "    (120, 180),\n",
    ")\n",
    "azimuth_set_names = (\n",
    "    \"1\",\n",
    "    \"2\",\n",
    "    \"3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell automatically checks your azimuth set inputs for basic errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(azimuth_set_ranges) == len(azimuth_set_names)\n",
    "for set_range in azimuth_set_ranges:\n",
    "    assert len(set_range) == 2\n",
    "    assert isinstance(set_range, tuple)\n",
    "\n",
    "assert all([isinstance(val, str) for val in azimuth_set_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Network and automatically determine branches and nodes\n",
    "network = Network(\n",
    "    traces,\n",
    "    area,\n",
    "    name=name,\n",
    "    # NOTE: branches and nodes not determined\n",
    "    determine_branches_nodes=False,\n",
    "    snap_threshold=0.001,\n",
    "    azimuth_set_ranges=azimuth_set_ranges,\n",
    "    azimuth_set_names=azimuth_set_names,\n",
    "    # If the target area is a circle, can be changed to True\n",
    "    circular_target_area=False,\n",
    "    # If you do not want to crop traces to the target area, pass False here:\n",
    "    truncate_traces=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rose plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot azimuth rose plot of fracture traces\n",
    "azimuth_bin_dict, fig, ax = network.plot_trace_azimuth()\n",
    "save_fig(fig, results_dir, \"trace_length_weighted_rose_plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.trace_azimuth_set_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trace length distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit for traces\n",
    "fit_traces = network.trace_lengths_powerlaw_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot length distribution fits (powerlaw, exponential and lognormal) of fracture traces\n",
    "fit, fig, ax = network.plot_trace_lengths()\n",
    "save_fig(fig, results_dir, \"trace_length_distribution_fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_powerlaw_fit(fit, network, line_type):\n",
    "    # Fit properties\n",
    "    print(f\"Automatically determined powerlaw cut-off: {fit.xmin}\")\n",
    "    print(f\"Powerlaw exponent: {fit.alpha - 1}\")\n",
    "    description = getattr(network, f\"{line_type}_lengths_powerlaw_fit_description\")\n",
    "    # TODO: Bug in fractopo, branch description is not labeled as a property (2.2.2022)\n",
    "    description = description if not callable(description) else description()\n",
    "\n",
    "    proportion = description[f\"{line_type} lengths cut off proportion\"]\n",
    "    print(f\"Proportion of data cut off by cut off: {proportion}\")\n",
    "    comparison = (\n",
    "        description[f\"{line_type} power_law vs. lognormal R\"],\n",
    "        description[f\"{line_type} power_law vs. lognormal p\"],\n",
    "    )\n",
    "    print(f\"Compare powerlaw fit to lognormal: R, p = {comparison}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "describe_powerlaw_fit(fit_traces, network, \"trace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save traces, branches and nodes.\n",
    "as_gpkg_and_shp(network.trace_gdf, \"traces\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip the folder in results.\n",
    "base_zip_path = Path(\"results\") / f\"{name}\"\n",
    "full_zip_path = base_zip_path.with_suffix(\".zip\")\n",
    "if full_zip_path.exists():\n",
    "    full_zip_path.unlink()\n",
    "make_archive(base_zip_path, \"zip\", results_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
